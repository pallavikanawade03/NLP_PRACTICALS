# NLP_PRACTICALS
#NLP Assignments using NLTK, PyTorch, and Advanced Models This repository contains a series of assignments for learning and practicing core Natural Language Processing (NLP) concepts using Python libraries like NLTK, scikit-learn, Gensim, and PyTorch. It spans basic tokenization, stemming, lemmatization, Bag-of-Words models, Transformer implementation from scratch, and advanced NLP tasks like sentiment analysis and N-gram-based auto-completion.

ðŸ“‚ Assignment List

Tokenization and Stemming using NLTK Tokenization Methods: Whitespace Punctuation-based Treebank Tweet Multi-Word Expression (MWE)
Stemming: Porter Stemmer Snowball Stemmer

Lemmatization: Using WordNet Lemmatizer or spaCy

Feature Extraction: BoW, TF-IDF, Word2Vec Bag-of-Words (BoW): Count Occurrence Normalized Count Occurrence TF-IDF Vectorization
Word2Vec Embedding: Trained using gensim.models.Word2Vec

Text Preprocessing & Representation Text Cleaning: Lowercasing, punctuation & number removal Lemmatization (any method, e.g., spaCy or NLTK) Stop Words Removal Label Encoding for categories TF-IDF Representation saved as a .csv or .pkl file

Transformer from Scratch (PyTorch) Custom Implementation of a Transformer model using PyTorch Scaled dot-product attention Positional encoding Multi-head attention Feedforward layers Encoder/Decoder architecture

Morphology using Add-Delete Table Study of Morphological Analysis Construction of words using roots, prefixes, suffixes Add-Delete Table to visualize inflectional and derivational changes

Advanced Sentiment Analysis Using pre-trained models or fine-tuned deep learning models like: BERT, RoBERTa, or DistilBERT Libraries: transformers, torch, sklearn

N-Gram based Auto-complete System Implementation of N-gram Model (unigram, bigram, trigram) Used for: Text auto-completion Author identification Basic machine translation Speech recognition prototype
