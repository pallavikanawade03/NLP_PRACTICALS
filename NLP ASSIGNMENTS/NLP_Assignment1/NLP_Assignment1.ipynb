{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8LvB20-NnqZ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer, TweetTokenizer\n",
        "from nltk.tokenize.mwe import MWETokenizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OSs9e7XPPoB",
        "outputId": "838eb25d-d16d-45bc-e4fa-10c6d2445f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLTK is a powerful library for NLP! It's easy-to-use and supports multiple tokenization techniques.\""
      ],
      "metadata": {
        "id": "0KTIWuaKPf8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "whitespace_tokenizer = WhitespaceTokenizer()\n",
        "punct_tokenizer = WordPunctTokenizer()\n",
        "treebank_tokenizer = TreebankWordTokenizer()\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "mwe_tokenizer = MWETokenizer([(\"easy\", \"to\", \"use\")])"
      ],
      "metadata": {
        "id": "9dLVIMKXPwob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Whitespace Tokenization:\", whitespace_tokenizer.tokenize(text))\n",
        "print(\"Punctuation-based Tokenization:\", punct_tokenizer.tokenize(text))\n",
        "print(\"Treebank Tokenization:\", treebank_tokenizer.tokenize(text))\n",
        "print(\"Tweet Tokenization:\", tweet_tokenizer.tokenize(text))\n",
        "print(\"MWE Tokenization:\", mwe_tokenizer.tokenize(text.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWd9ORDvP35O",
        "outputId": "5c8bfae5-9098-4354-8d7b-8da6b5d889b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP!', \"It's\", 'easy-to-use', 'and', 'supports', 'multiple', 'tokenization', 'techniques.']\n",
            "Punctuation-based Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '!', 'It', \"'\", 's', 'easy', '-', 'to', '-', 'use', 'and', 'supports', 'multiple', 'tokenization', 'techniques', '.']\n",
            "Treebank Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '!', 'It', \"'s\", 'easy-to-use', 'and', 'supports', 'multiple', 'tokenization', 'techniques', '.']\n",
            "Tweet Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '!', \"It's\", 'easy-to-use', 'and', 'supports', 'multiple', 'tokenization', 'techniques', '.']\n",
            "MWE Tokenization: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP!', \"It's\", 'easy-to-use', 'and', 'supports', 'multiple', 'tokenization', 'techniques.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "porter = PorterStemmer()\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "\n",
        "words = [\"running\", \"flies\", \"easily\", \"studies\"]\n",
        "print(\"Porter Stemmer:\", [porter.stem(word) for word in words])\n",
        "print(\"Snowball Stemmer:\", [snowball.stem(word) for word in words])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W85oORZmP9u8",
        "outputId": "5bfff1b3-5073-4e20-806d-baabd9aec1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer: ['run', 'fli', 'easili', 'studi']\n",
            "Snowball Stemmer: ['run', 'fli', 'easili', 'studi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(\"Lemmatization:\", [lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-HFaCdQChL",
        "outputId": "6ec09616-b080-4b2b-89b1-742ad836c31d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatization: ['running', 'fly', 'easily', 'study']\n"
          ]
        }
      ]
    }
  ]
}